import re
import urllib3
import pandas as pd # Импортируем библиотеку обработки и анализа данных pandas
import numpy as np  # Импортируем библиотеку numpy

!pip install selenium               

urls = ["https://www.kinopoisk.ru/film/88"+str(i) for i in range(3)] # Генерируем ссылки для кинопоиска

def get_ratio(web_page):
  ratio = wd.find_elements_by_xpath("//span[@class='rating_ball']")   
  ratio = [x.text for x in ratio]                                     
  return ratio[0]                                                     

def get_name(wd):
  t = wd.find_elements_by_xpath("//div[@class='name']")               
  titles = [x.text.replace('\n',';') for x in t]                     
                                                                     
  titles = titles[0].split(';')                                      
  name = titles[0]                                                   
  return name 

def get_year_moto(web_page):
  t = wd.find_elements_by_xpath("//table[@class='info']")           
  titles = [x.text.replace('\n',' ') for x in t]                    
                                                                    
  titles = titles[0].split(',')                                     
  year = int(re.findall('[0-9]+',titles[0])[0])                     
  moto = find_moto(titles)                                          

  return year, moto

def get_description(wd):
  scrapped = wd.find_elements_by_xpath("//div[@class='brand_words film-synopsys']")                  
  description = [x.text for x in scrapped]                                                          
  return description                                                                                   

def find_moto(titles):
  
  for i in range(len(titles)-1):                                   
      if 'слоган' in titles[i]:                                    
          moto = titles[i].split('«')[1][:-1]                      
          break                                                    
      else:
          moto = '-'                                               
          
  return moto


# Объединить всю информацию в удобный вид
def get_information(url):
  result = []                                                       

  timeout = 20                                                     
  try:
    WebDriverWait(wd, timeout)                                      
  except TimeoutException:
    print("Превышено время ожидания")
    wd.quit()                                                      

  wd.get(url)                                                      
  result.append(get_name(wd))                                      
  year, moto = get_year_moto(wd)                                   
  result.append(year)                                              
  result.append(moto)                                              
  result.append(get_description(wd))                               
  result.append(get_ratio(wd))                                     

  
  return result

from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException

options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
wd = webdriver.Chrome('chromedriver',options=options)

print(wd.page_source)  # Посмотрим, как все открывается

# Пробегаемся по всем ссылкам
scraped_data = [get_information(url) for url in urls]           
# Преобразуем в массив
movie_array = np.array(scraped_data)
# Преобразуем в датафрейм
movie_frame = pd.DataFrame({"Название":[item[0] for item in movie_array],
                            "Год выхода":[item[1] for item in movie_array],
                            "Слоган":[item[2] for item in movie_array],
                            "Описание":[item[3] for item in movie_array]
                            })
